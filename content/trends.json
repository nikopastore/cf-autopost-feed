#!/usr/bin/env python3
# Pulls public Google News RSS for career topics and writes content/trends.json

import json, time, urllib.parse, urllib.request, xml.etree.ElementTree as ET, os

QUERIES = [
    "resume OR interview OR job search",
    "salary negotiation OR pay transparency",
    "hiring trends OR job market OR layoffs OR openings"
]
def fetch_feed(q):
    url = "https://news.google.com/rss/search?q=" + urllib.parse.quote(q) + "&hl=en-US&gl=US&ceid=US:en"
    with urllib.request.urlopen(url, timeout=20) as r:
        return r.read()

def parse_feed(xml_bytes):
    items=[]
    root = ET.fromstring(xml_bytes)
    for it in root.findall(".//item"):
        title = (it.findtext("title") or "").strip()
        link  = (it.findtext("link") or "").strip()
        src   = (it.findtext("{http://news.google.com}source") or "Google News").strip()
        if title and link:
            items.append({"title":title, "link":link, "source":src})
    return items

all_items=[]
for q in QUERIES:
    try:
        xml = fetch_feed(q)
        all_items += parse_feed(xml)[:10]
        time.sleep(1)
    except Exception as e:
        print("Fetch error:", e)

os.makedirs("content", exist_ok=True)
with open("content/trends.json","w",encoding="utf-8") as f:
    json.dump(all_items[:25], f, ensure_ascii=False, indent=2)
print("Wrote content/trends.json with", len(all_items[:25]), "items")
